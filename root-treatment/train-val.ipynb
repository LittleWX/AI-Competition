{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from dataset import voc\n",
    "from retinanet import model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "tag = 'debug'\n",
    "split_name = 'voc-1'\n",
    "root_path = '/home/voyager/data/root/voc/'\n",
    "\n",
    "device_name = 'cuda'\n",
    "batch_size = 4\n",
    "epochs = 30\n",
    "depth = 50\n",
    "lr = 1e-5\n",
    "patience = 3\n",
    "image_size=512\n",
    "\n",
    "# info and deps\n",
    "now = datetime.now()\n",
    "\n",
    "result_path = './{}_{}_{}'.format(\n",
    "    tag,\n",
    "    split_name,\n",
    "    now.strftime('%Y%m%d_%H%M%S')\n",
    ")\n",
    "\n",
    "summary_writer = SummaryWriter(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "# train\n",
    "\n",
    "# TODO : transforms for train\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = voc.VOCDetection(\n",
    "    root_path,\n",
    "    image_set=\"{}_train\".format(split_name),\n",
    "    transforms=train_trans\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=voc.collate\n",
    ")\n",
    "\n",
    "# val\n",
    "\n",
    "# TODO : transforms for val\n",
    "val_trans = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_set = voc.VOCDetection(\n",
    "    root_path,\n",
    "    image_set=\"{}_val\".format(split_name),\n",
    "    transforms=val_trans\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=voc.collate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss and optimizer\n",
    "\n",
    "device = torch.device(device_name)\n",
    "\n",
    "if depth == 34:\n",
    "    net = model.resnet34(train_set.num_classes(), pretrained=True)\n",
    "elif depth == 50:\n",
    "    net = model.resnet50(train_set.num_classes(), pretrained=True)\n",
    "elif depth == 101:\n",
    "    net = model.resnet101(train_set.num_classes(), pretrained=True)\n",
    "elif depth == 152\n",
    "    net = model.resnet12(train_set.num_classes(), pretrained=True)\n",
    "    \n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net).to(device)\n",
    "net.training = True\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    patience=patience,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "net.train()\n",
    "net.module.freezee_bn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-val loop\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    net.module.freeze_bn()\n",
    "    \n",
    "    epoch_loss = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            classification_loss, regression_loss = retinanet([\n",
    "                data['imgs'].to(device),\n",
    "                data['annos']\n",
    "            ])\n",
    "            \n",
    "            classification_loss = classification_loss.mean()\n",
    "            regression_loss = regression_loss.mean()\n",
    "            \n",
    "            loss = classification_loss + regression_loss\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            if loss == 0:\n",
    "                continue\n",
    "                \n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 0.1)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # TODO : log\n",
    "            \n",
    "            del classification_loss\n",
    "            del regression_loss\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "    for i, data in enumerate(val_loader):\n",
    "        # TODO : val\n",
    "        pass\n",
    "    \n",
    "    scheduler.step(np.mean(epoch_loss))\n",
    "    \n",
    "    # TODO : save checkpoint\n",
    "    \n",
    "    # TODO : write summary for tensorboardX\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
