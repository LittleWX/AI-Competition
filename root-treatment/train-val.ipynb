{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from dataset import voc\n",
    "from retinanet import model, val\n",
    "from retinanet import transforms as aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consts\n",
    "tag = 'debug'\n",
    "split_name = 'voc-1'\n",
    "root_path = '/home/voyager/data/root/voc/'\n",
    "\n",
    "device_name = 'cpu'\n",
    "batch_size = 2\n",
    "depth = 50\n",
    "\n",
    "epochs = 500\n",
    "lr = 1e-5\n",
    "patience = 3\n",
    "\n",
    "image_size = 512\n",
    "num_classes = 2\n",
    "num_workers = 8\n",
    "\n",
    "# info and deps\n",
    "now = datetime.now()\n",
    "\n",
    "if not os.path.exists('./result'):\n",
    "    os.mkdir('./result')\n",
    "\n",
    "result_path = './result/{}_{}_{}_{}'.format(\n",
    "    tag,\n",
    "    depth,\n",
    "    split_name,\n",
    "    now.strftime('%Y%m%d_%H%M%S')\n",
    ")\n",
    "\n",
    "summary_writer = SummaryWriter(result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "# train\n",
    "\n",
    "# transforms for train\n",
    "train_trans = aug.Compose([\n",
    "    aug.RandomCropAndPad(),\n",
    "    aug.Pad(), # pad to square image\n",
    "    aug.Resize(image_size, image_size),\n",
    "    aug.RandomFlipLeftRight(0.5),\n",
    "    aug.RandomFlipUpDown(0.5),\n",
    "    aug.RandomRotate(5),\n",
    "    aug.RandomTranslatePc(50, 50),\n",
    "    aug.AutoLevel(min_level_rate=1, max_level_rate=1),\n",
    "    aug.AutoContrast(),\n",
    "    aug.RandomContrast(0.5),\n",
    "    aug.Contrast(1.25),\n",
    "    aug.RandomChoice([\n",
    "        aug.RandomSaltPepperNoise(0.9, 0.5),\n",
    "        aug.RandomSaltPepperNoise(0.95, 0.5),\n",
    "        aug.RandomSaltPepperNoise(0.99, 0.5)\n",
    "    ]),\n",
    "    aug.ToTensor(),\n",
    "    # aug.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) # mean and std of pretrained model\n",
    "])\n",
    "\n",
    "train_set = voc.VOCDetection(\n",
    "    root_path,\n",
    "    image_set=\"{}_train\".format(split_name),\n",
    "    transforms=train_trans\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=voc.collate,\n",
    "    num_workers=num_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss and optimizer\n",
    "\n",
    "device = torch.device(device_name)\n",
    "\n",
    "if depth == 34:\n",
    "    net = model.resnet34(num_classes, pretrained=True)\n",
    "elif depth == 50:\n",
    "    net = model.resnet50(num_classes, pretrained=True)\n",
    "elif depth == 101:\n",
    "    net = model.resnet101(num_classes, pretrained=True)\n",
    "elif depth == 152:\n",
    "    net = model.resnet152(num_classes, pretrained=True)\n",
    "    \n",
    "net = net.to(device)\n",
    "# net = torch.nn.DataParallel(net).to(device)\n",
    "net.training = True\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    patience=patience,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "net.train()\n",
    "net.freeze_bn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/634 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voyager/anaconda3/envs/pytorch_0.4.1/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n",
      "  1%|          | 4/634 [00:23<1:02:49,  5.98s/it]"
     ]
    }
   ],
   "source": [
    "# train-val loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('training epoch {}:'.format(epoch))\n",
    "    \n",
    "    # train\n",
    "    net.train()\n",
    "    net.freeze_bn()\n",
    "    \n",
    "    epoch_loss = []\n",
    "    \n",
    "    with tqdm(total=len(train_loader)) as pbar:\n",
    "        for i, data in enumerate(train_loader):\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # convert annos to focal loss format - [x1, y1, x2, y2, cls]\n",
    "                batch_annos = []\n",
    "                max_anno_count = 0\n",
    "\n",
    "                for batch in range(len(data[1])):\n",
    "                    bboxes = data[1][batch][1]\n",
    "                    bboxes = bboxes.to(dtype=torch.long)\n",
    "                    labels = data[1][batch][0]\n",
    "                    labels = labels.to(dtype=torch.long)\n",
    "\n",
    "                    # bboxes.shape = [4, n]\n",
    "                    bboxes = torch.t(bboxes)\n",
    "                    # labels.shape = [1, n]\n",
    "                    labels = torch.unsqueeze(labels, 0)\n",
    "\n",
    "                    # annos.shape = [n, 5]\n",
    "                    annos = torch.cat((bboxes, labels), 0)\n",
    "                    annos = torch.t(annos)\n",
    "\n",
    "                    # record max anno count\n",
    "                    anno_count = annos.shape[0]\n",
    "\n",
    "                    if anno_count > max_anno_count:\n",
    "                        max_anno_count = anno_count\n",
    "\n",
    "                    batch_annos.append(annos)\n",
    "\n",
    "                dummy_anno = torch.tensor([[0, 0, 0, 0, -1]])\n",
    "                padded_batch_annos = []\n",
    "\n",
    "                for anno in batch_annos:\n",
    "                    if anno.shape[0] < max_anno_count:\n",
    "                        dummy_count = max_anno_count - anno.shape[0]\n",
    "\n",
    "                        for i in range(dummy_count):\n",
    "                            anno = torch.cat((anno, dummy_anno), 0)\n",
    "\n",
    "                    padded_batch_annos.append(anno)\n",
    "\n",
    "                padded_batch_annos = torch.stack(padded_batch_annos)\n",
    "                padded_batch_annos = padded_batch_annos.to(dtype=torch.float32)\n",
    "\n",
    "                # forward\n",
    "                classification_loss, regression_loss = net([\n",
    "                    data[0].to(device),\n",
    "                    padded_batch_annos\n",
    "                ])\n",
    "\n",
    "                classification_loss = classification_loss.mean()\n",
    "                regression_loss = regression_loss.mean()\n",
    "\n",
    "                loss = classification_loss + regression_loss\n",
    "                epoch_loss.append(loss.item())\n",
    "\n",
    "                if loss == 0:\n",
    "                    continue\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(net.parameters(), 0.1)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                del classification_loss\n",
    "                del regression_loss\n",
    "                \n",
    "                pbar.update(1)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                break\n",
    "\n",
    "    # epoch-wise work and record\n",
    "    mean_loss = np.mean(epoch_loss)\n",
    "    print('epoch avg loss: {}'.format(mean_loss))\n",
    "\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "    # save checkpoint\n",
    "    torch.save(net, os.path.join(result_path, '{:0>3}_{:1.4f}.pth'.format(\n",
    "        epoch,\n",
    "        mean_loss\n",
    "    )))\n",
    "\n",
    "    # write summary for tensorboardX\n",
    "    summary_writer.add_scalar(\n",
    "        '/train/loss',\n",
    "        mean_loss,\n",
    "        epoch\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
